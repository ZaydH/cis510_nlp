\section{Risk estimation}\label{sec:RiskEstimators}

Let~$\func{\dec}{\domainX}{\real}$ be a decision function from feature vector~$\X$ to a real number, and let~$\func{\loss}{\domainX \times \domainY}{\real_{{\geq}0}}$ be the loss function.  \textit{Risk estimator},~$\risk$,\footnote{Although expected risk~$\risk$ is a function of~$\dec$ as shown in Eq.~\eqref{eq:RiskEstimator:Expectation}, we drop~$\dec$ from our notation for brevity going forward.} quantifies $\dec$'s~expected loss formally as

\begin{equation}\label{eq:RiskEstimator:Expectation}
  \risk(\dec) = \mathbb{E}_{(\X,\y) \sim \joint}\sbrack{\floss{\decX}{\y}}\text{.}
\end{equation}

Since $\joint$~is unknown, $\risk$~is also unknown so in practice empirical estimate,~$\emprisk$ is used.  This section provides an overview of the PN, PU (specifically nnPU), and PUbN risk estimators as well as their empirical estimates.\footnote{All empirical risk estimates described here support both batch and stochastic gradient descent.}

\subsection{PN --- positive-negative}

PN~classification has access to both positive and negative labeled examples.  Therefore, Eq.~\eqref{eq:RiskEstimator:Expectation} exactly specifies its expected risk.

\paragraph{Empirical Estimation} Estimating the PN~empirical risk is straightforward as shown in Eq.~\eqref{eq:EmpRisk:PN}; it is merely the mean loss for all examples in~$\train$.  This formulation applies irrespective of any covariate shift.

\begin{equation}\label{eq:EmpRisk:PN}
  \emprisk = \frac{1}{\abs{\train}} \sum_{(\X,\y) \in \train} \floss{\decX}{\y}
\end{equation}

\subsection{nnPU --- non-negative positive-unlabeled}

Since positive\-/unlabeled~(PU) learning has no negative labeled examples, traditional supervised learning cannot be used. By Bayes' Rule in Eq.~\eqref{eq:Joint:Bayes}, the expected risk can be decomposed into the risk associated with each label (positive and negative) as shown in Eq.~\eqref{eq:Risk:Bayes}.  ${\varrisk{D}{\ypred}}$ denotes the expected loss when predicting label~$\ypred$ for samples drawn from distribution~${\pDist_{D}}$ where ${D \in \set{\textnormal{P}, \textnormal{N}, \X}}$.

\begin{align}
  \risk &= \prior \mathbb{E}_{\X \sim \pcond}\sbrack{\floss{\decX}{\pcls}} + (1-\prior) \mathbb{E}_{\X \sim \ncond}\sbrack{\floss{\decX}{\ncls}} \nonumber \\
        &= \prior \prisk{P} + (1-\prior) \nrisk{N} \label{eq:Risk:Bayes}
\end{align}

Since the unlabeled set is drawn from marginal distribution,~$\marginal$, it is clear that:

\begin{align}
  \nrisk{U} &= \mathbb{E}_{\X \sim \marginal} \sbrack{\floss{\X}{\ncls}} \nonumber \\
            &= \prior \mathbb{E}_{\X \sim \pcond} \sbrack{\floss{\X}{\ncls}} + (1 - \prior) \mathbb{E}_{\X \sim \ncond} \sbrack{\floss{\X}{\ncls}}\nonumber \\
            &= \prior \nrisk{P} + (1 - \prior) \nrisk{N} \label{eq:Risk:Unlabeled}
\end{align}

\noindent
Rearranging the above and combining it with Eq.~\eqref{eq:Risk:Bayes} yields the unbiased positive\-/unlabeled~(uPU) risk estimator below.~\cite{duPlessis:2014}

\begin{equation}\label{eq:Risk:uPU}
  \risk = \prior \prisk{P} + \nrisk{U} - \prior \nrisk{P}
\end{equation}

\paragraph{Non\-/negativity} By the definitions of~$\loss$ and~$\risk$, it is clear that $\nrisk{N}$~must be non\-/negative.  However, highly expressive learners (e.g.,~neural networks) often cause ${\nrisk{U} - \prior \nrisk{P}}$ to slip negative --- primarily due to overfitting.  Kiryo\etal~\cite{Kiryo:2017} proposed the non\-/negative positive\-/unlabeled~(nnPU) risk estimator in Eq.~\eqref{eq:Risk:nnPU}; the primary difference versus uPU is the negative risk surrogate is explicitly forced non\-/negative by the~$\max$.

\begin{equation}\label{eq:Risk:nnPU}
  \risk = \prior \prisk{P} + \max\left\{0, \nrisk{U} - \prior \nrisk{P} \right\}
\end{equation}

Whenever the negative risk surrogate is less than~0, nnPU updates the model parameters using special gradient ${-\gamma \nabla_{\theta} \prior \nrisk{P} - \nrisk{U}}$ where hyperparameter~${\gamma \in (0,1]}$ is used to attenuate the learning rate.  Observe that the negative risk surrogate is deliberately negated; this is done to ``defit'' the learner so that it no longer under estimates the negative class' expected risk.

Although forcing~$\nrisk{N}$'s surrogate to be non-negative introduces an estimation bias (i.e.,~expected value does not equal the true expectation), nnPU often performs better in practice and guarantees ERM uniform convergence.

\paragraph{Empirical Estimation} Each risk term in nnPU can be empirically estimated from the training set where:

\begin{equation}\label{eq:EmpRisk:Pos}
  \evrisk{P}{\ypred} = \frac{1}{\abs{\ptrain}} \sum_{\X \in \ptrain} \floss{\decX}{\ypred}
\end{equation}

\noindent
and for unlabeled set ${\utrain \sim \marginal}$,

\begin{equation}
  \evrisk{U}{-} = \frac{1}{\abs{\utrain}} \sum_{\X \in \utrain} \floss{\decX}{\ncls} \text{.}
\end{equation}

\noindent
Prior~$\prior$ and attenuator~$\gamma$ are hyperparameters.

\subsection{PUbN --- positive, unlabeled, biased-negative}

Let $\latent$~be a latent random variable representing whether tuple~${(\X,\y)}$ is eligible for labeling.  Joint distribution then becomes,~${\trijoint = \pDist(\X, \y, \latent)}$, trivariate.  By definition, ${\pDist(\latent = \pcls \vert \X, \y = \pcls) = 1}$ (i.e.,~no positive selection bias) or equivalently ${\pDist(\y = \ncls \vert \X, \latent = \ncls) = 1}$.  The biased negative conditional distribution is therefore~${\bncond = \pDist(\X \vert \y = \ncls, \latent = \pcls)}$.

The marginal distribution can be partitioned as

\begin{equation*}
  \begin{aligned}
    \marginal = &\pDist(\y = \pcls) \pDist(\X \vert \y = \pcls) \\
                &+ \underbrace{\pDist(\y = \ncls, \latent = \pcls)}_{\plabel}\pDist(\X \vert \y = \ncls, \latent = \pcls)
                + \underbrace{\pDist(\y = \ncls, \latent = \ncls)}_{1 - \prior - \plabel} \pDist(\X \vert \y = \ncls, \latent = \ncls)
  \end{aligned}
\end{equation*}

\noindent
where ${\plabel = \pDist(\y = \ncls, \latent = \pcls)}$ is a hyperparameter. The expected risk therefore becomes

\begin{equation}\label{eq:Risk:WithBN}
  \risk = \prior \prisk{P} + \plabel \nrisk{bN} + (1 - \prior - \rho) \smrisk
\end{equation}

Define ${\sigma(\X) = \pDist(\latent = \pcls \vert \X)}$.  While the proof is well beyond the scope of this document, Hsieh\etal~\cite{Hsieh:2018} proved that with guaranteed estimation error bounds $\smrisk$~decomposes as

\begin{equation}\label{eq:ExpectedRisk:PUbN:Latent}
  \begin{aligned}
    \smrisk = &\mathbb{E}_{\X \sim \marginal}\sbrack{\mathbbm{1}_{\sigX \leq \eta} \floss{\decX}{\ncls} \sigdiff} \\
              &+ \prior \mathbb{E}_{\X \sim \pcond} \sbrack{\mathbbm{1}_{\sigX > \eta} \floss{\decX}{\ncls} \frac{\sigdiff}{\sigX}} \\
              &+ \plabel \mathbb{E}_{\X \sim \bncond} \sbrack{\mathbbm{1}_{\sigX > \eta} \floss{\decX}{\ncls} \frac{\sigdiff}{\sigX}}
  \end{aligned}
\end{equation}

\noindent
where $\mathbbm{1}$~is the indicator function and $\eta$~is a hyperparameter that controls the importance of unlabeled data versus $\textnormal{P}$/$\textnormal{bN}$ data.

\paragraph{Empirical Estimation} Similar to nnPU, $\prisk{P}$~and~$\nrisk{bN}$ can be estimated directly from~$\ptrain$ and~$\bntrain$ respectively.  Estimating~$\smrisk$ is more challenging and actually requires the training of two classifiers.

First, $\sigX$~is empirically estimated by training a positive\-/unlabeled probabilistic classifier with labeled set ${\ptrain \sqcup \bntrain}$ and unlabeled set~$\utrain$; refer to this learned approximation as~$\hsigX$.  Probabilistic classifiers must be adequately calibrated to generate probabilities.  Hsieh\etal\ tried to achieve this by training with the logistic loss but that provides no calibration guarantees.~\cite{Guo:2017}

Rather than specifying hyperparameter~$\eta$ directly, Hsieh\etal\ instead specified hyperparameter~$\tau$ to calculate~$\eta$ via

\begin{equation}\label{eq:EtaCalculation}
  \abs{\setbuild{\X \in \utrain}{\hsigX \leq \eta}} = \tau (1 - \prior - \plabel)\abs{\utrain} \text{.}
\end{equation}

\noindent
This approach provides a more intuitive view into the balance between~$\utrain$ and $\ptrain$/$\bntrain$.

PUbN's second classifier minimizes Eq.~\eqref{eq:Risk:WithBN} and empirically estimates the risk when ${\latent = \ncls}$ as

\begin{equation}\label{eq:EmpRisk:PUbN:Latent}
  \begin{aligned}
    \smrisk = &\frac{1}{\abs{\utrain}} \sum_{\xvar{U} \in \utrain} \sbrack{\mathbbm{1}_{\hsig(\xvar{U}) \leq \eta} \floss{\dec(\xvar{U})}{\ncls} \big(1 - \hsig(\xvar{U})\big)} \\
              &+\frac{\prior}{\abs{\ptrain}} \sum_{\xvar{P} \in \ptrain} \sbrack{\mathbbm{1}_{\hsig(\xvar{P}) > \eta} \floss{\dec(\xvar{P})}{\ncls} \frac{1 - \hsig(\xvar{P})}{\hsig(\xvar{P})}} \\
              &+\frac{\plabel}{\abs{\bntrain}} \sum_{\xvar{bN} \in \bntrain} \sbrack{\mathbbm{1}_{\hsig(\xvar{bN}) > \eta} \floss{\dec(\xvar{bN})}{\ncls} \frac{1 - \hsig(\xvar{bN})}{\hsig(\xvar{bN})}} \text{.}
  \end{aligned}
\end{equation}
