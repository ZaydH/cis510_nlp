\section{Experimental results}\label{sec:ExperimentalResults}

We compare the performance of the PN, nnPU, and~PUbN risk estimators on both proposed neural architectures.  The experiments are modeled after the setup in~\cite{Hsieh:2018}.

For each labeled set (e.g.,~$\ptrain$, $\bntrain$,~$\ntrain$), 500~training examples were sampled from the corresponding conditional distribution.  The unlabeled training set consisted of 6,000~elements.

All learners were trained for 50 epochs. A disjoint validation set -- one-fifth the training set's size -- was used to select the best epoch. The training set's risk was based on the logistic loss.  The validation's set risk was based on the sigmoid loss to ensure no single example has an outsized impact on model selection.

The hyperparameters we tuned work were learning rate ${\alpha \in \set{5 \cdot 10^{-3}, 10^{-3}, 5 \cdot 10^{-4}}}$, ${\tau \in \set{0.5, 0.7, 0.9}}$, and ${\gamma \in \set{0.1, 0.3, 0.5, 0.7, 0.9, 1}}$.  Each architecture and risk estimator pairing's optimal hyperparameter setting was selected using a grid search to find the minimum average validation loss.

\subsection{Baselines}

The PN~learners serve as the performance baselines.  Unbiased~PN -- where ${\ptrain \sim \pcond}$ and ${\ntrain \sim \ncond}$ -- represents each architecture's performance ceiling given~$\abs{\ptrain}$ and~$\abs{\ntrain}$.

Biased~PN follows an identical training procedure to its unbiased counterpart with the exception that ${\bntrain \sim \bncond}$~is used instead of $\ntrain$.  Since biased~PN is the simplest approach -- both theoretically and in implementation, one would expect it would be handily outperformed by slower, more advanced risk estimators like~nnPU and~PUbN.

\subsection{Selection bias profiles}

Recall that under covariate shift, only the marginal distributions change.  As shown in Table~\eqref{tab:ExperimentResults}, we achieve this by modifying the prior probabilities of each of the three negative categories.  The extent to which each category is biased can be determined by comparing the experiment biases to Table~\ref{tab:ExperimentalResults}.

Our selection biases are of two variants -- each stressing different estimator limitations.  In the first two experiments, the biased negative set is drawn from only one negative category, i.e.,~sci.\ and~talk.\ respectively.  The second experiment variant draws training examples from all negative categories but shifts the prior probabilities.

nnPU is unaffected by the biased negative set since it considers only~$\ptrain$ and~$\utrain$.  Unbiased~PN (by definition) does not consider~$\bntrain$.  Therefore, only a single result per architecture is reported for those two risk estimators.

\subsection{Architecture performance comparison}

Tables~\ref{tab:ExperimentalResults:LSTM} and~\ref{tab:ExperimentalResults:ELMo} enumerate the test set (inductive) accuracy results for the~LSTM and preprocessed\-/ELMo architectures respectively.  Across all risk estimators and selection biases, the ELMo~preprocessed architecture performed substantially better than the LSTM model (\red{XXXXX Add statistic}).

ELMo's performance advantage most likely derives from its superior harnessing of transfer learning.  This indicates that when dealing with limited or biased labeled data, transfer learning importance's can dominate even sophisticated approaches to address those limitations/biases.

We exclusively discuss the ELMo architecture going forward due to its vastly superior performance.

\subsection{Risk estimator comparison}

Table~\ref{tab:ExperimentalResults:ELMo}'s first two rows show that when the biased negative set is drawn from only a single negative category, PUbN had the best performance.  When the biased negative set was drawn from all negative categories, biased~PN had the best results.

To summarize formally, the most important factor in determining the best risk estimator is the extent to which the negative class-conditional distribution's support is covered.  Selecting all labeled examples from a single categories entails that a PN~learner has no guidance on how to classify examples from the remaining two negative categories.  That is why biased~PN performed so poorly in the first two experiments.

In contrast when $\btrain$~has labeled examples from all categories, it is able to learn how to predict all variants and can outperform even classifiers that are provided information about the bias like~PUbN.

\begin{table}[t]
  \caption{20~newsgroups negative covariate shift test set accuracy results for the two classifier architectures and three bias configurations. Listed below each category name is its biased prior probability in that experiment. The corresponding labeling probability~$\plabel$ is also provided. The best performing learners are bolded.}\label{tab:ExperimentalResults}
  \begin{subtable}[t]{\textwidth}
    \centering
    \caption{End-to-end LSTM architecture results}\label{tab:ExperimentalResults:LSTM}
    \input{tables/lstm_results.tex}
  \end{subtable}

  \begin{subtable}[t]{\textwidth}
    \centering
    \caption{Preprocessed\-/ELMo architecture results averaged across 10~independent trials}\label{tab:ExperimentalResults:ELMo}
    \input{tables/elmo_results.tex}
  \end{subtable}
\end{table}
